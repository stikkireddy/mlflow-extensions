{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04ff8475-4ef9-4e74-8a5f-8ea226081dfa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow-extensions\n",
    "%pip install mlflow -U\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0465704d-7555-4fcd-8cfb-de63d5efb12a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow_extensions.databricks.deploy.ez_deploy import EzDeploy\n",
    "from mlflow_extensions.databricks.prebuilt import prebuilt\n",
    "\n",
    "deployer = EzDeploy(\n",
    "    config=prebuilt.audio.vllm.FIXIE_ULTRA_VOX_0_4_64K_CONFIG,\n",
    "    registered_model_name=\"main.default.sri_ultravox_audio_text_to_text_model\"\n",
    ")\n",
    "\n",
    "deployer.download()\n",
    "\n",
    "deployer.register()\n",
    "\n",
    "endpoint_name = \"sri_ultravox_audio_text_to_text_model\"\n",
    "\n",
    "deployer.deploy(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a054e91d-04a6-4fb7-ac3b-230ee8baee59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "\n",
    "def encode_audio_base64_from_url(audio_url: str) -> str:\n",
    "    \"\"\"Encode an audio retrieved from a remote url to base64 format.\"\"\"\n",
    "\n",
    "    with requests.get(audio_url) as response:\n",
    "        response.raise_for_status()\n",
    "        result = base64.b64encode(response.content).decode('utf-8')\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# gettysburg.wav is a 17 second audio file\n",
    "audio_data = encode_audio_base64_from_url(\"https://www2.cs.uic.edu/~i101/SoundFiles/gettysburg.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b4766a0-8760-4f5b-b225-393791513e67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow_extensions.serving.compat.openai import OpenAI\n",
    "from mlflow_extensions.databricks.prebuilt import prebuilt\n",
    "from mlflow.utils.databricks_utils import get_databricks_host_creds\n",
    "\n",
    "workspace_host = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "endpoint_name = \"sri_ultravox_audio_text_to_text_model\"\n",
    "endpoint_url = f\"https://{workspace_host}/serving-endpoints/{endpoint_name}/invocations\"\n",
    "\n",
    "token = get_databricks_host_creds().token\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=endpoint_url,\n",
    "    api_key=token\n",
    ")\n",
    "\n",
    "model_name = prebuilt.audio.vllm.FIXIE_ULTRA_VOX_0_4_64K_CONFIG.engine_config.model\n",
    "\n",
    "chat_completion_from_base64 = client.chat.completions.create(\n",
    "    messages=[{\n",
    "        \"role\":\n",
    "            \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Breakdown the content of the audio?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"audio_url\",\n",
    "                \"audio_url\": {\n",
    "                    # Any format supported by librosa is supported\n",
    "                    \"url\": f\"data:audio/ogg;base64,{audio_data}\"\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    }],\n",
    "    model=model_name,\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "result = chat_completion_from_base64.choices[0].message.content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "890deb7f-58d9-4a4c-b136-3148b7102079",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow_extensions.serving.compat.openai import OpenAI\n",
    "from mlflow_extensions.databricks.prebuilt import prebuilt\n",
    "from mlflow.utils.databricks_utils import get_databricks_host_creds\n",
    "\n",
    "workspace_host = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "endpoint_name = \"sri_ultravox_audio_text_to_text_model\"\n",
    "endpoint_url = f\"https://{workspace_host}/serving-endpoints/{endpoint_name}/invocations\"\n",
    "\n",
    "token = get_databricks_host_creds().token\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=endpoint_url,\n",
    "    api_key=token\n",
    ")\n",
    "\n",
    "model_name = prebuilt.audio.vllm.FIXIE_ULTRA_VOX_0_4_64K_CONFIG.engine_config.model\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal, List\n",
    "\n",
    "\n",
    "class AudioExtraction(BaseModel):\n",
    "    year: str\n",
    "    speaker: str\n",
    "    location: str\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]\n",
    "    tone: Literal[\"somber\", \"upbeat\", \"pessemistic\"]\n",
    "    summary: str\n",
    "\n",
    "\n",
    "chat_completion_from_base64 = client.chat.completions.create(\n",
    "    messages=[{\n",
    "        \"role\":\n",
    "            \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"Extract the following content from the audio: {str(AudioExtraction.schema())}?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"audio_url\",\n",
    "                \"audio_url\": {\n",
    "                    # Any format supported by librosa is supported\n",
    "                    \"url\": f\"data:audio/ogg;base64,{audio_data}\"\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    }],\n",
    "    model=model_name,\n",
    "    max_tokens=512,\n",
    "    extra_body={\n",
    "        \"guided_json\": AudioExtraction.schema()\n",
    "    }\n",
    ")\n",
    "\n",
    "result = chat_completion_from_base64.choices[0].message.content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a73f071c-3e30-474b-90b3-df1204c0fed3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04-getting-started-ultravox",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
